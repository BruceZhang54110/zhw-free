logging:
  level:
    root: info
  file:
    path: ./logs

spring:
  redis:
    cluster:
      nodes: 192.168.199.165:6391,192.168.199.165:6392,192.168.199.165:6393,192.168.199.165:6394,192.168.199.165:6395,192.168.199.165:6396
      max-redirects: 3
    lettuce:
      pool:
        max-active: 32
        min-idle: 8
        max-wait: 10000
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/zhw-free?serverTimezone=UTC&characterEncoding=utf8&useUnicode=true&useSSL=false
    username: root
    password: 123456
  rabbitmq:
    addresses: 81.70.194.5:5672
    username: admin
    password: admin
    virtual-host: /
    connection-timeout: 15000
  kafka:
    bootstrap-servers: 192.168.0.103:9092,192.168.0.103:9093,192.168.0.103:9094
    producer:
      ## 发送消息失败时的重试次数
      retries: 0
      ## 批量发送数据的配置
      batch-size: 16384
      ## 设置kafka生产者缓存区大小
      buffer-memory: 33554432
      ## kafka消息序列化
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      ## 0: 生产者成功写入消息之前不会等待任何来自服务器的响应
      ## 1： 只要集群的leader节点收到消息，生产者就会收到来自服务器的成功响应
      ## -1： 表示分区leader必须等待消息被成功写入所有的ISR副本(同步副本) 中才认为pruducer请求成功。这种方案提过最高的消息可靠性保证，但是理论上吞吐率也是最差的。
      acks: -1
    consumer:
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      enable-auto-commit: false
      auto-commit-interval: 100
server:
  servlet:
    context-path: /
  port: 8001
mybatis-plus:
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
